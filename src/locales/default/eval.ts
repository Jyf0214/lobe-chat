export default {
  'benchmark.actions.delete.confirm':
    'Are you sure you want to delete this benchmark? Related datasets and evaluation records will also be deleted.',
  'benchmark.actions.delete.title': 'Delete',
  'benchmark.actions.export': 'Export',
  'benchmark.card.bestScore': 'Best',
  'benchmark.card.caseCount': '{{count}} cases',
  'benchmark.card.datasetCount': '{{count}} datasets',
  'benchmark.card.empty': 'No evaluations yet',
  'benchmark.card.emptyHint': 'Create a new evaluation from the benchmark detail page',
  'benchmark.card.importDataset': 'Import Dataset',
  'benchmark.card.noDataset': 'No datasets yet',
  'benchmark.card.noDatasetHint': 'Import a dataset to start evaluating',
  'benchmark.card.recentRuns': 'Recent Evaluations',
  'benchmark.card.runCount': '{{count}} evals',
  'benchmark.card.startFirst': 'Start First Evaluation',
  'benchmark.card.viewAll': 'View all {{count}}',
  'benchmark.create.confirm': 'Create',
  'benchmark.create.description.label': 'Description',
  'benchmark.create.description.placeholder': 'Benchmark description (optional)',
  'benchmark.create.error': 'Failed to create benchmark',
  'benchmark.create.identifier.label': 'Identifier',
  'benchmark.create.identifier.placeholder': 'benchmark-identifier',
  'benchmark.create.identifierRequired': 'Please enter an identifier',
  'benchmark.create.name.label': 'Name',
  'benchmark.create.name.placeholder': 'Enter benchmark name',
  'benchmark.create.nameRequired': 'Please enter a benchmark name',
  'benchmark.create.success': 'Benchmark created successfully',
  'benchmark.create.tags.label': 'Tags',
  'benchmark.create.tags.placeholder': 'Add tags, separate with comma or space',
  'benchmark.create.title': 'Create Benchmark',
  'benchmark.detail.backToOverview': 'Back to Overview',
  'benchmark.detail.datasetCount':
    '{{count}} dataset{{count, plural, one {} other {s}}} in this benchmark',
  'benchmark.detail.runCount':
    '{{count}} evaluation run{{count, plural, one {} other {s}}} on this benchmark',
  'benchmark.detail.stats.bestScore': 'Best Score',
  'benchmark.detail.stats.cases': 'Cases',
  'benchmark.detail.stats.datasets': 'Datasets',
  'benchmark.detail.stats.runs': 'Runs',
  'benchmark.detail.stats.tags': 'Tags',
  'benchmark.detail.stats.totalCases': 'Total Cases',
  'benchmark.detail.tabs.data': 'Data',
  'benchmark.detail.tabs.datasets': 'Datasets',
  'benchmark.detail.tabs.runs': 'Runs',
  'benchmark.empty': 'No benchmarks yet. Create one to get started.',

  'caseDetail.actual': 'Actual Output',
  'caseDetail.chatArea.title': 'Conversation',
  'caseDetail.cost': 'Cost',
  'caseDetail.difficulty': 'Difficulty',
  'caseDetail.duration': 'Duration',
  'caseDetail.expected': 'Expected Output',
  'caseDetail.failureReason': 'Failure Reason',
  'caseDetail.input': 'Input',
  'caseDetail.judgeComment': 'Judge Comment',
  'caseDetail.resources': 'Resources',
  'caseDetail.score': 'Score',
  'caseDetail.tokens': 'Token Usage',

  'dataset.actions.addDataset': 'Add Dataset',
  'dataset.actions.import': 'Import Data',
  'dataset.actions.importDataset': 'Import Dataset',
  'dataset.empty': 'No datasets',
  'dataset.empty.description': 'Import a dataset to start building this benchmark',
  'dataset.empty.title': 'No datasets yet',
  'dataset.import.choices': 'Choices',
  'dataset.import.confirm': 'Import',
  'dataset.import.context': 'Context',
  'dataset.import.error': 'Failed to import dataset',
  'dataset.import.expected': 'Expected Answer',
  'dataset.import.expectedDelimiter': 'Answer Delimiter',
  'dataset.import.expectedDelimiter.desc': 'Split multi-candidate answers by this delimiter',
  'dataset.import.expectedDelimiter.placeholder': 'e.g. | or ,',
  'dataset.import.fieldMapping': 'Field Mapping',
  'dataset.import.fieldMapping.desc': 'Map file columns to test case fields. "Input" is required.',
  'dataset.import.ignore': 'Ignore',
  'dataset.import.input': 'Input',
  'dataset.import.metadata': 'Metadata',
  'dataset.import.next': 'Next',
  'dataset.import.parseError': 'Failed to parse file',
  'dataset.import.parsing': 'Parsing file...',
  'dataset.import.prev': 'Previous',
  'dataset.import.preview': 'Data Preview',
  'dataset.import.preview.desc': 'Confirm the mapping is correct, then import.',
  'dataset.import.preview.rows': '{{count}} rows total',
  'dataset.import.sortOrder': 'Sort Order',
  'dataset.import.step.mapping': 'Map Fields',
  'dataset.import.step.preview': 'Preview',
  'dataset.import.step.upload': 'Upload File',
  'dataset.import.success': 'Successfully imported {{count}} test cases',
  'dataset.import.title': 'Import Dataset',
  'dataset.import.upload.hint': 'Supports CSV, XLSX, JSON, JSONL',
  'dataset.import.upload.text': 'Click or drag file here to upload',
  'dataset.import.uploading': 'Uploading...',
  'dataset.switchDataset': 'Switch Dataset',

  'difficulty.easy': 'Easy',
  'difficulty.hard': 'Hard',
  'difficulty.medium': 'Medium',

  'overview.createBenchmark': 'Create Benchmark',
  'overview.importDataset': 'Import Dataset',
  'overview.subtitle': 'Benchmark and evaluate your AI agents across datasets',
  'overview.title': 'Evaluation Lab',

  'run.actions.abort': 'Abort',
  'run.actions.abort.confirm': 'Are you sure you want to abort this evaluation?',
  'run.actions.create': 'New Evaluation',
  'run.actions.delete': 'Delete',
  'run.actions.delete.confirm': 'Are you sure you want to delete this evaluation?',
  'run.empty.description': 'Start your first evaluation run on this dataset',
  'run.empty.descriptionBenchmark': 'Start your first evaluation run on this benchmark',
  'run.empty.title': 'No runs yet',
  'run.config.agentId': 'Target Agent',
  'run.config.concurrency': 'Concurrency',
  'run.config.judgeModel': 'Judge Model',
  'run.config.model': 'Model',
  'run.config.temperature': 'Temperature',
  'run.config.timeout': 'Timeout',
  'run.create.title': 'New Evaluation',
  'run.detail.caseResults': 'Case Results',
  'run.detail.charts': 'Charts',
  'run.detail.config': 'Evaluation Config',
  'run.detail.overview': 'Overview',
  'run.metrics.avgScore': 'Avg Score',
  'run.metrics.cost': 'Cost',
  'run.metrics.duration': 'Duration',
  'run.metrics.passRate': 'Pass Rate',

  'sidebar.benchmarks': 'Benchmarks',
  'sidebar.dashboard': 'Dashboard',

  'run.status.aborted': 'Aborted',
  'run.status.completed': 'Completed',
  'run.status.failed': 'Failed',
  'run.status.idle': 'Idle',
  'run.status.pending': 'Pending',
  'run.status.running': 'Running',

  'table.columns.difficulty': 'Difficulty',
  'table.columns.duration': 'Duration',
  'table.columns.input': 'Input',
  'table.columns.score': 'Score',
  'table.columns.status': 'Status',
  'table.columns.tags': 'Tags',

  'table.filter.all': 'All',
  'table.filter.failed': 'Failed',
  'table.filter.passed': 'Passed',
  'table.search.placeholder': 'Search cases...',

  'testCase.preview.expected': 'Expected',
  'testCase.preview.input': 'Input',
  'testCase.preview.title': 'Test Case Preview',
  'testCase.search.placeholder': 'Search cases...',
};
